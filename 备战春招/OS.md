

# 内存管理

## 分段/分页

**分段** 和 **分页** 是计算机内存管理中的两种重要机制，用于将进程的地址空间映射到物理内存中。它们有不同的特点和用途，以下是详细的解释：

---

### 1. 分段 (Segmentation)

![image-20241219150908385](https://typora-dusong.oss-cn-chengdu.aliyuncs.com/image-20241219150908385.png)

- 概念

分段是一种按照逻辑功能划分内存空间的技术。进程的地址空间被分成若干逻辑片段，每个片段对应特定的功能，比如代码段、数据段、堆栈段等。每个段独立管理，可以动态调整大小。

- 特点

1. **逻辑划分**：基于程序的逻辑结构（如代码段、数据段）进行划分。  
2. **段表**：每个段都有一个段描述符，段描述符包含段基地址和段长度，段表用于记录这些信息。  
3. **地址结构**：逻辑地址由两个部分组成：  
   - **段号（Segment Number）**：指明访问的是哪个段。  
   - **段内偏移（Offset）**：指定段内的具体地址。  
4. **内存分配灵活**：不同段可以分配在物理内存的不同位置，且大小可以动态调整。

- 优点

  - 容易满足程序的逻辑需求，程序更易开发和维护。

  - 支持不同段的权限管理（如代码段只读、数据段可读写）。


- 缺点
  - 内存碎片问题：由于段大小不固定，容易出现外部碎片。


---

### 2. 分页 (Paging)

![image-20241219151031830](https://typora-dusong.oss-cn-chengdu.aliyuncs.com/image-20241219151031830.png)

<u>页表是存储在内存里的，**内存管理单元** （*MMU*）就做将虚拟内存地址转换成物理地址的工作。</u>

- 概念

分页是将内存划分为固定大小的块（称为页框或帧），同时将进程的地址空间划分为等大小的页。分页的目的是实现更高效的内存利用。

- 特点

1. **固定大小**：页和页框的大小固定（通常是 4KB 或更大）。  
2. **页表**：记录每个逻辑页与物理页框的映射关系。  
3. **地址结构**：逻辑地址分为两部分：  
   - **页号（Page Number）**：指明逻辑地址属于哪个页。  
   - **页内偏移（Offset）**：指明页内的具体地址。  
4. **连续性不要求**：逻辑页在物理内存中可以不连续，解决了外部碎片问题。

- 优点

  - 有效减少外部碎片问题。

  - 更容易实现虚拟内存。


- 缺点

  - 页表可能占用较多内存，尤其是进程地址空间很大时。

  - 存取时间增加：每次内存访问需要查页表，可能引入额外的延迟。


---

### 3. 分段 vs 分页

| **特性**       | **分段 (Segmentation)**          | **分页 (Paging)**                  |
| -------------- | -------------------------------- | ---------------------------------- |
| **内存划分**   | 按逻辑划分（代码段、数据段等）   | 按固定大小划分（页和页框）         |
| **碎片问题**   | 易出现外部碎片                   | 主要有内部碎片                     |
| **地址结构**   | 段号 + 段内偏移                  | 页号 + 页内偏移                    |
| **连续性要求** | 段内地址必须连续                 | 页在物理内存中不要求连续           |
| **实现复杂度** | 较高，需管理段表                 | 较低，需管理页表                   |
| **适用场景**   | 强调逻辑结构，适用于复杂应用程序 | 强调内存利用率，适用于现代操作系统 |

---

### 4. 分段和分页的结合

现代操作系统（如 Linux、Windows）通常结合分段和分页：  
- **分段** 提供逻辑上的内存划分（如不同的代码段和数据段）。  
- **分页** 解决内存分配





## 内存满了会发生什么？ —— 缺页中断处理过程

<img src="https://cdn.xiaolincoding.com//mysql/other/2f61b0822b3c4a359f99770231981b07.png" alt="img" style="zoom:50%;" />

当应用程序读写了这块虚拟内存，CPU 就会去访问这个虚拟内存， 这时会发现这个虚拟内存没有映射到物理内存， CPU 就会产生**缺页中断**，进程会从用户态切换到内核态，并将缺页中断交给内核的 Page Fault Handler （缺页中断函数）处理。

缺页中断处理函数会看是否有空闲的物理内存，如果有，就直接分配物理内存，并建立虚拟内存与物理内存之间的映射关系。

如果没有空闲的物理内存，那么内核就会开始进行**回收内存**的工作，回收的方式主要是两种：直接内存回收和后台内存回收。

- **后台内存回收**（kswapd）：在物理内存紧张的时候，会唤醒 kswapd 内核线程来回收内存，这个回收内存的过程**异步**的，不会阻塞进程的执行。
- **直接内存回收**（direct reclaim）：如果后台异步回收跟不上进程内存申请的速度，就会开始直接回收，这个回收内存的过程是**同步**的，会阻塞进程的执行。

如果直接内存回收后，空闲的物理内存仍然无法满足此次物理内存的申请，那么内核就会放最后的大招了 ——**触发 OOM （Out of Memory）机制**。

OOM Killer 机制会根据算法选择一个占用物理内存较高的进程，然后将其杀死，以便释放内存资源，如果物理内存依然不足，OOM Killer 会继续杀死占用物理内存较高的进程，直到释放足够的内存位置。



### 哪些内存会被回收？

主要有两类内存可以被回收，而且它们的回收方式也不同。

- **文件页**（File-backed Page）：内核缓存的磁盘数据（Buffer）和内核缓存的文件数据（Cache）都叫作文件页。大部分文件页，都可以直接释放内存，以后有需要时，再从磁盘重新读取就可以了。而那些被应用程序修改过，并且暂时还没写入磁盘的数据（也就是脏页），就得先写入磁盘，然后才能进行内存释放。所以，**回收干净页的方式是直接释放内存，回收脏页的方式是先写回磁盘后再释放内存**。
- **匿名页**（Anonymous Page）：这部分内存没有实际载体，不像文件缓存有硬盘文件这样一个载体，比如堆、栈数据等。这部分内存很可能还要再次被访问，所以不能直接释放内存，它们**回收的方式是通过 Linux 的 Swap 机制**，Swap 会把不常访问的内存先写到磁盘中，然后释放这些内存，给其他更需要的进程使用。再次访问这些内存时，重新从磁盘读入内存就可以了。

文件页和匿名页的回收都是基于 LRU 算法，也就是优先回收不常访问的内存。



## 在4G物理内存机器上申请8G空间

![image-20241219150104704](https://typora-dusong.oss-cn-chengdu.aliyuncs.com/image-20241219150104704.png)

- 在 32 位操作系统，因为进程理论上最大能申请 3 GB 大小的虚拟内存，所以直接申请 8G 内存，会申请失败。
- 在 64位 位操作系统，因为进程理论上最大能申请 128 TB 大小的虚拟内存，即使物理内存只有 4GB，申请 8G 内存也是没问题，因为申请的内存是虚拟内存。如果这块虚拟内存被访问了，要看系统有没有 Swap 分区：
  - 如果没有 Swap 分区，因为物理空间不够，进程会被操作系统杀掉，原因是 OOM（内存溢出）；
  - 如果有 Swap 分区，即使物理内存只有 4GB，程序也能正常使用 8GB 的内存，进程可以正常运行；





## 预读失效/缓存污染

> 前提：
>
> 1. 磁盘读取效率远小于内存读取，在内存中有一个缓冲空间==（ Linux 的 Page Cache 和 MySQL 的 Buffer Pool 缓存）==用于缓存磁盘数据，通常使用LRU算法进行页面淘汰机制
>
> 2. 由于操作系统空间局部性原理（靠近当前被访问数据的数据，在未来很大概率会被访问到），Linux 操作系统为基于 Page Cache 的读缓存机制提供**预读机制**，比如当读取4KB时，会加载相邻的16KB数据到buffer中
>
>    ![img](https://cdn.xiaolincoding.com//mysql/other/ae8252378169c8c14b8b9907983f7d8b.png)

传统的 LRU 算法法无法避免下面这两个问题：

- 预读失效导致缓存命中率下降；
- 缓存污染导致缓存命中率下降；



### 预读失效

> [!NOTE]
>
> 什么是：**不会被访问的预读页却占用了 LRU 链表前排的位置，而末尾淘汰的页，可能是热点数据，这样就大大降低了缓存命中率**

为了避免「预读失效」造成的影响，Linux 和 MySQL 对传统的 LRU 链表做了改进：

- Linux 操作系统实现两个了 LRU 链表：**活跃 LRU 链表（active list）和非活跃 LRU 链表（inactive list）**。
- MySQL Innodb 存储引擎是在一个 LRU 链表上划分来 2 个区域：**young 区域 和 old 区域**。





### 缓存污染

> [!NOTE]
>
> 什么是：当我们在批量读取数据的时候，由于数据被访问了一次，这些大量数据都会被加入到「活跃 LRU 链表」里，然后之前缓存在活跃 LRU 链表（或者 young 区域）里的热点数据全部都被淘汰了，**如果这些大量的数据在很长一段时间都不会被访问的话，那么整个活跃 LRU 链表（或者 young 区域）就被污染了**。

为了避免「缓存污染」造成的影响，Linux 操作系统和 MySQL Innodb 存储引擎分别提高了升级为热点数据的门槛：

- Linux 操作系统：在内存页被访问**第二次**的时候，才将页从 inactive list 升级到 active list 里。

  （但是如果还是使用「只要数据被访问一次，就将数据加入到活跃 LRU 链表头部（或者 young 区域）」这种方式的话，那么还存在缓存污染的问题。）

- MySQL Innodb：在内存页被访问

  第二次

  的时候，并不会马上将该页从 old 区域升级到 young 区域，因为还要进行

  停留在 old 区域的时间判断：

  - 如果第二次的访问时间与第一次访问的时间**在 1 秒内**（默认值），那么该页就**不会**被从 old 区域升级到 young 区域；
  - 如果第二次的访问时间与第一次访问的时间**超过 1 秒**，那么该页就**会**从 old 区域升级到 young 区域；

通过提高了进入 active list （或者 young 区域）的门槛后，就很好了避免缓存污染带来的影响。





## 🆕🌟Page cache

Page Cache 的本质是由 Linux 内核管理的内存区域，由多个 page （文件页 & 匿名页）构成（page 是内存管理分配的基本单位）

> ```text
> Page Cache = Buffers + Cached + SwapCached
> ```





## 🆕🌟调用 read() 或 write() 系统调用的过程

1. **用户态到内核态的切换**：通过系统调用陷入内核，执行相应的内核处理函数。
2. **内核操作**：验证文件描述符、查找文件结构、执行文件或设备驱动的读写操作、更新文件偏移量等。
3. **返回用户态**：执行完系统调用后，返回结果并切换回用户态。

# 进程&线程

## 进程资源申请了什么

1. **CPU 资源**（程序计数器、寄存器）
2. **内存资源**（代码段、数据段、堆、栈）
3. **文件和 I/O 资源**（文件描述符、标准输入/输出）
4. **进程控制块（PCB）**（进程 ID、状态、调度信息）

5. **IPC 资源**（共享内存、信号量、管道等）

6. **线程资源**（如果是多线程进程）



- 进程可以包含多个线程，每个线程共享进程的地址空间和部分资源（如文件描述符），但有自己的**线程栈和寄存器上下文**。

## fork原理

1. **创建一个新的进程结构**

​	•	内核分配一个新的 **进程控制块（PCB）**，用于存储子进程的进程信息。

​	•	子进程的 PCB 复制自父进程的 PCB，但某些字段会被修改，如 **进程 ID（PID）** 和 **父进程 ID（PPID）**。

2. **复制父进程的虚拟内存**

​	•	**代码段（Text Segment）：** 共享（通常是只读的）。

​	•	**数据段（Data Segment）：** 复制（写时复制，Copy-On-Write）。

​	•	**堆（Heap）：** 复制（写时复制）。

​	•	**栈（Stack）：** 复制（写时复制）。

3. **复制文件描述符表**

​	•	子进程继承父进程打开的文件，指向相同的文件对象（内核的 file 结构）。

​	•	但是，文件偏移量、读写权限等信息是独立维护的。

4. **复制进程状态**

​	•	子进程从 fork() 之后的代码继续执行，但 fork() **返回值不同**：

​	•	**父进程得到子进程的 PID**（正数）。

​	•	**子进程得到 0**，表示它是新创建的进程。

​	•	**失败返回 -1**，表示 fork() 失败（通常是系统资源不足）。

5. **调度子进程**

​	•	fork() 结束后，操作系统可能会立即调度子进程运行，也可能继续执行父进程，取决于调度策略。

### 🆕🌟vfork与fork的区别

fork 和 vfork 都是用来创建新进程的系统调用，但它们在行为和效率上有显著的区别。以下是它们的主要区别：

**1️⃣ fork**

```c
#include <unistd.h>
#include <stdio.h>

int main() {
    pid_t pid = fork();
    
    if (pid == -1) {
        perror("fork failed");
        return 1;
    }
    
    if (pid == 0) {
        // 子进程执行的代码
        printf("Child process\n");
    } else {
        // 父进程执行的代码
        printf("Parent process\n");
    }

    return 0;
}
```

**2️⃣ vfork**

```c
#include <unistd.h>
#include <stdio.h>

int main() {
    pid_t pid = vfork();
    
    if (pid == -1) {
        perror("vfork failed");
        return 1;
    }
    
    if (pid == 0) {
        // 子进程执行的代码
        printf("Child process\n");
        // 在子进程中执行exec或exit
        execlp("/bin/ls", "ls", NULL);
    } else {
        // 父进程代码会在子进程执行exec或exit后执行
        printf("Parent process\n");
    }

    return 0;
}
```

**fork 与 vfork 的主要区别**

| **特性**       | fork                                       | vfork                                                      |
| -------------- | ------------------------------------------ | ---------------------------------------------------------- |
| **资源复制**   | 父进程的资源被复制到子进程（通过写时复制） | 子进程共享父进程的地址空间，直到调用exec或exit             |
| **父进程行为** | 父进程继续执行，子进程从fork返回的地方执行 | 父进程被挂起，直到子进程调用exec或exit                     |
| **效率**       | 较低（由于资源的复制）                     | 较高（没有资源复制的开销）                                 |
| **使用场景**   | 一般用于创建子进程并让子进程独立执行       | 主要用于子进程立即执行exec或exit，提高效率                 |
| **安全性**     | 子进程和父进程相互独立，可以自由地修改资源 | 需要小心，子进程在父进程地址空间中运行，可能影响父进程数据 |

**什么时候使用 vfork 或 fork**

​	•	**使用fork**：当你需要创建一个完全独立的子进程，且子进程需要修改父进程的资源（例如文件描述符、内存等），或者子进程执行的任务较为复杂时，应该使用fork。这样每个进程都有自己的资源和内存空间，不会互相干扰。

​	•	**使用vfork**：如果你创建子进程的目的是立即执行一个新程序（使用exec），并且不打算修改父进程的资源，使用vfork可以提高效率。由于子进程会共享父进程的地址空间，只有在调用exec后才会切换到新的程序，因此vfork能避免复制父进程的开销。

**总结**

​	•	fork 会创建一个完全独立的子进程，适合用在需要子进程独立执行任务的情况。

​	•	vfork 优化了效率，通过让子进程共享父进程的地址空间来避免资源复制，适合用于子进程执行exec等操作的场景。



你在项目中有涉及进程创建和管理的相关需求吗？

## 上下文切换

- 上下文切换场景：1️⃣时间片耗尽 2️⃣所需系统资源不足 3️⃣主动挂起sleep 4️⃣有更高优先级进程运行 5️⃣硬件中断
- 上下文切换了什么：
  - 进程：CPU寄存器、pc、页表、堆栈、其他与进程相关的资源（如文件描述符表）。
  - 线程：CPU寄存器、pc、栈指针

## 进程、线程、协程区别

进程：操作系统分配资源的基本单位。

线程：操作系统调度的基本单位。

协程：一种轻量级的用户态线程。

- 区别：1️⃣ 调度方式、2️⃣ 切换开销、3️⃣资源独立性、4️⃣通信开销、5️⃣ 内存占用

  6️⃣适用场景：

  > 进程：
  >
  > ​	•	**独立的应用程序**：每个应用程序通常作为一个进程运行，例如浏览器、编辑器、数据库等。
  >
  > ​	•	**操作系统级别的任务**：比如，操作系统会将不同的任务或服务分配给不同的进程来提高安全性和稳定性。
  >
  > ​	•	**高隔离需求**：需要严格的资源隔离或容错能力的场景，比如不同的安全权限的应用程序运行。
  >
  > 线程：
  >
  > ​	•	**多任务并发处理**：比如多线程服务器，可以同时处理多个请求，提高并发性能。
  >
  > ​	•	**计算密集型任务**：当程序需要进行大量的计算并且可以并行化时，多线程可以充分利用多核CPU资源。
  >
  > ​	•	**I/O密集型任务**：如网络请求、磁盘读写等场景，通过多线程可以在等待I/O操作的过程中同时处理其他任务，提高程序响应性。
  >
  > ​	•	**实时处理**：如游戏引擎中常见的渲染线程、物理计算线程、音效处理线程等，每个线程处理不同的任务，确保系统高效实时响应。



- 进程: 进程是具有一定独立功能的程序，进程是系统资源分配和调度的最小单位。每个进程都有自己的独立内存空间，不同进程通过进程间通信来通信。由于进程比较重量，占据独立的内存，所以上下文进程间的切换开销（栈、寄存器、虚拟内存、文件句柄等）比较大，但相对比较稳定安全。
- 线程: 线程是进程的一个实体,线程是内核态,而且是CPU调度和分派的基本单位,它是比进程更小的能独立运行的基本单位。线程间通信主要通过共享内存，上下文切换很快，资源开销较少，但相比进程不够稳定容易丢失数据。

- 协程: 协程是一种用户态的轻量级线程，协程的调度完全是由用户来控制的。协程拥有自己的寄存器上下文和栈。协程调度切换时，将寄存器上下文和栈保存到其他地方，在切回来的时候，恢复先前保存的寄存器上下文和栈，直接操作栈则基本没有内核切换的开销，可以不加锁的访问全局变量，所以上下文的切换非常快。

## 🌟为什么要分用户线程和内核线程

在操作系统中，将线程分为**用户线程（User Thread）和内核线程（Kernel Thread）**，主要是为了**平衡性能与系统控制**，具体原因如下：

**1️⃣ 用户线程（User Thread）**

**用户线程**是在**用户空间**实现的线程，由**用户态的线程库（如 pthread、Go runtime 等）**管理，**操作系统内核对其不可见**。

✅ **特点：**

​	•	**创建、销毁、切换开销小**（因为不涉及系统调用）

​	•	**不需要内核支持**，在不支持线程的 OS 上也能运行

​	•	**切换速度快**，因为不需要切换到内核态

​	•	**多个用户线程可能映射到一个内核线程（M:N 线程模型）**

❌ **缺点：**

​	•	**无法利用多核**，因为 OS 只调度内核线程

​	•	**如果一个用户线程阻塞（如 I/O 操作），整个进程可能都会被阻塞**

​	•	**需要用户态调度器**，复杂度增加

**2️⃣ 内核线程（Kernel Thread）**

**内核线程**由**操作系统内核管理和调度**，可以直接使用 OS 提供的调度机制。

✅ **特点：**

​	•	**支持真正的并行执行**（可利用多核 CPU）

​	•	**一个线程阻塞不会影响其他线程**

​	•	**OS 负责管理，调度公平**

❌ **缺点：**

​	•	**创建和切换开销大**（涉及系统调用和上下文切换）

​	•	**需要 OS 支持，消耗更多资源**

​	•	**系统调用会影响线程的执行效率**

**3️⃣ 为什么要区分用户线程和内核线程？**

📌 **1. 提高性能**：用户线程切换不需要陷入内核，减少上下文切换开销。

📌 **2. 兼容性**：用户线程可以在不支持多线程的 OS 上运行。

📌 **3. 灵活性**：用户线程可以实现自己的调度策略，如协程（goroutine）。

📌 **4. 利用多核**：内核线程可以让多个线程并行运行，提高多核利用率。

**4️⃣ 常见线程模型**

​	1.	**1:1（每个用户线程对应一个内核线程）**

​	•	优点：可以利用多核

​	•	缺点：线程创建和切换成本高（如 pthread 线程）

​	2.	**M:N（多个用户线程映射到多个内核线程）**

​	•	优点：兼顾性能和并行度

​	•	缺点：调度复杂（如 Go 的 Goroutine）

​	3.	**N:1（多个用户线程映射到一个内核线程）**

​	•	优点：切换快，创建成本低

​	•	缺点：无法利用多核（如 Java 早期的 Green Threads）

📌 **总结**：

​	•	**用户线程适用于轻量级并发（如协程、事件驱动模型）**

​	•	**内核线程适用于 CPU 计算密集型任务和 I/O 密集型任务（如数据库、多线程服务器）**

​	•	**现代语言（如 Go）通常采用 M:N 线程模型，以兼顾效率和灵活性**  



## 调度算法

- **先来先服务**（First Come First Serve, FCFS）
- **最短作业优先** （Shortest Job First，SJF）
- **高响应比优先** （Highest Response Ratio Next, HRRN）：（等待时间 + 运行时间）/ 运行时间
- **时间片轮转**（Round Robin, RR）
- **最高优先级调度算法**（Highest Priority First，HPF）：静态优先级/动态优先级、 抢占式/非抢占式
- **多级反馈队列调度算法**（Multilevel Feedback Queue）：多个队列，每个队列优先级从高到低，同时优先级越高时间片越短。如果有新的进程加入优先级高的队列时，立刻停止当前正在运行的进程，转而去运行优先级高的队列

## 进程间通信

1️⃣ 管道（匿名/命名） 2️⃣ 消息队列 3️⃣ 信号量 4️⃣ 信号  5️⃣ 共享内存 6️⃣ socket

### 哪一个最快

**共享内存（Shared Memory）——最快的 IPC 方式 🚀**

**原因**：进程间通信的主要瓶颈是**数据拷贝**和**上下文切换**。共享内存允许多个进程直接访问同一块内存，而**不需要数据拷贝**，因此速度最快。

**特点**：

✅ 速度最快，因为数据不需要在进程间传输，直接在共享区域读取/写入。

✅ 适用于**大数据量**的进程间通信（如视频帧共享、数据库缓存）。

❌ 需要**同步机制**（如信号量、互斥锁）来避免竞争条件。

❌ 实现稍复杂，应用场景有限。

**示例（Linux 下使用 mmap 共享内存）：**

```c
#include <stdio.h>
#include <stdlib.h>
#include <sys/mman.h>
#include <sys/stat.h>
#include <fcntl.h>
#include <unistd.h>
#include <string.h>

int main() {
    int fd = shm_open("/shm_example", O_CREAT | O_RDWR, 0666);
    ftruncate(fd, 1024);
    void *ptr = mmap(0, 1024, PROT_READ | PROT_WRITE, MAP_SHARED, fd, 0);
    sprintf(ptr, "Hello, Shared Memory!");
    munmap(ptr, 1024);
    close(fd);
    return 0;
}
```

### 匿名和命名管道的区别



## 经典同步问题

### 哲学家就餐问题

<img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E4%BA%92%E6%96%A5%E4%B8%8E%E5%90%8C%E6%AD%A5/23-%E5%93%B2%E5%AD%A6%E5%AE%B6%E8%BF%9B%E9%A4%90%E6%A8%A1%E5%9E%8B.jpg" alt="哲学家就餐的问题" style="zoom:50%;" />



- 方法一：通过信号量表示叉子是否可用(方法1、2、3)，每个人依次拿左右手的叉子，最后会导致<u>死锁</u>
- 方法二：在方法一的基础上对整个操作加锁，虽然避免了死锁但是<u>一次只能有一个哲学家就餐</u>
- 方法三：破坏循环等待的条件，根据位置的奇偶，依次拿起左右手叉子的顺序不同
- 方法四：通过信号量表示哲学家是否就餐，使用三个状态表示哲学家当前行为（think、eat、hungry），只有当附近哲学家均未就餐并且自己为hungry状态时才就餐P(s[i]) （信号量初始值为0，若没有叉子会阻塞），就餐完成之后执行P(s[i-1])、P(s[i+1])

### 读者-写者问题





# 页面置换/磁盘调度算法

## 页面置换算法

### 缺页异常处理流程

![缺页中断的处理流程](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost2/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E8%B0%83%E5%BA%A6%E7%AE%97%E6%B3%95/%E7%BC%BA%E9%A1%B5%E5%BC%82%E5%B8%B8%E6%B5%81%E7%A8%8B.png)

### 常见的页面置换算法

- **醉解页面置换算法**：置换掉未来最长时间不访问的页面
- **先进先出**
- **最近最久未使用（LRU）**：<u>导致预读失效和缓存污染问题</u>
- **时钟页面置换算法**：把页面放在一个环形链表中，每个节点设置一个<u>访问位</u>，当被访问时置1，发生缺页中断时，遍历节点，如果访问位为1，则置0； 若访问位为0，则将其淘汰
- **最不常用算法**：将访问次数最少的淘汰（考虑到小的时间范围内，访问次数高的问题，可以定期减少访问次数，如当发生时间中断时，访问次数除2）



## 磁盘调度算法

### 机械磁盘构造

![image-20250104131055960](https://typora-dusong.oss-cn-chengdu.aliyuncs.com/image-20250104131055960.png)

识别：盘片、磁头、磁道、扇区、柱面

### 调度算法

- **先来先服务**
- **最短寻道时间优先**：将请求访问位置与当前磁头位置计算差值，从小到大排序（<u>可能产生饥饿现象</u>）
- **扫描算法**：磁头在一个方向上移动，访问所有未完成的请求，直到磁头到达该方向上的**最后的磁道**，才调换方向，这就是扫描（Scan）算法。（<u>中间部分相比其他部分响应的频率会比较多</u>，也就是说每个磁道的响应频率存在差异）
- **循环扫描算法**：为解决每个磁道响应频率不一致问题，循环扫描钟<u>磁道只响应一个方向上的请求</u>
- **LOOK与C-LOOK算法**：前面说到的扫描算法和循环扫描算法，都是磁头移动到磁盘「最始端或最末端」才开始调换方向。那这其实是可以优化的，优化的思路就是**磁头在移动到「最远的请求」位置，然后立即反向移动。**





# I/O

## 零拷贝

### 传统I/O数据流

📌 **传统 I/O 的数据流**：

​	1.**磁盘 → 内核缓冲区**（DMA 传输）

​	2.**内核缓冲区 → 用户态缓冲区**（read() 触发拷贝）

​	3.**用户态缓冲区 → 内核网络缓冲区**（write() 触发拷贝）

​	4.**内核网络缓冲区 → 网卡（DMA 传输）**

### mmap + write

🔹 **原理**：使用 mmap() 将文件映射到用户态地址空间，然后直接 write() 发送到网络或磁盘。

```c
void *addr = mmap(NULL, length, PROT_READ, MAP_SHARED, fd, 0);
write(socket_fd, addr, length);
```



### sendfile

**🔹 mmap + sendfile 也是一种零拷贝方案：**

`mmap()` 将文件映射到用户态（避免 read()），`sendfile()` 直接从文件描述符发送数据（避免 write()）

```c
#include <sys/sendfile.h>
ssize_t sendfile(int out_fd, int in_fd, off_t *offset, size_t count);
```



<img src="https://typora-dusong.oss-cn-chengdu.aliyuncs.com/image-20250203%E4%B8%8B%E5%8D%88114424981.png" alt="image-20250203下午114424981" style="zoom:50%;" />

### splice

🔹 splice 直接在 **两个文件描述符（fd）** 之间传输数据，而 **不经过用户态**：

```c
splice(file_fd, NULL, pipe_fd[1], NULL, length, SPLICE_F_MOVE);
splice(pipe_fd[0], NULL, socket_fd, NULL, length, SPLICE_F_MOVE);
```

**🔹 数据流**

​	1.**磁盘 → 内核缓冲区**（通过 DMA 传输）

​	2.**内核缓冲区 → 管道缓冲区（通过 splice 直接传输）**

​	3.**管道缓冲区 → 网络缓冲区（通过 splice 直接传输）**

​	4.**网络缓冲区 → 网络接口（通过 DMA 传输）**

​	**灵活性高**：可以在多种文件描述符之间传输数据，如文件到管道、管道到网络。

### io_uring

🔹 **原理**：io_uring 通过 **共享环形缓冲区（ring buffer）** 提供高效的异步 I/O，并且支持零拷贝（IORING_OP_SEND_ZC）。

```c
struct io_uring_sqe *sqe = io_uring_get_sqe(&ring);
io_uring_prep_send_zc(sqe, socket_fd, data, len, 0);
io_uring_submit(&ring);
```

## select、poll、epoll的区别

**1️⃣ select**

​	•	**工作原理**：select 通过将文件描述符集合传入内核，内核监视这些文件描述符的状态变化（如可读、可写等）。当某个文件描述符的状态发生变化时，内核将通知用户进程。

**2️⃣ poll**

​	•	**工作原理**：poll 与 select 类似，但它使用一个 pollfd 结构数组来存储文件描述符信息。它不再受到 FD_SETSIZE 的限制，因此可以处理更多的文件描述符。

## io_uring

> 🔹 **io_uring 采用共享环形缓冲区（Shared Ring Buffer）**
>
> ​	•	用户态和内核态**共享两个环形队列**：
>
> ​	•	**提交队列（SQ, Submission Queue）**：用于存放用户提交的 I/O 请求
>
> ​	•	**完成队列（CQ, Completion Queue）**：用于存放内核完成的 I/O 结果
>
> ​	•	**用户态可以批量提交 I/O 请求**，内核异步处理，减少系统调用次数。
>
> ​	•	用户进程只需要一个 io_uring_enter() 调用即可提交多个请求，而不是为每个 I/O 操作都调用 read/write。
>
> 
>
> **异步 I/O 机制，避免阻塞**
>
> 🔹 **传统 I/O 是同步的（阻塞或非阻塞）**
>
> ​	•	传统 read()、write() 可能会因为数据未准备好而阻塞，导致 CPU 资源浪费。
>
> ​	•	即使使用 epoll 等 I/O 多路复用，仍然需要 epoll_wait() 轮询，仍然会有系统调用开销。
>
> 🔹 **io_uring 支持真正的异步 I/O**
>
> ​	•	用户进程提交 I/O 请求后，不需要等待内核处理，而是**立即返回**，继续执行其他任务。
>
> ​	•	内核在后台异步完成 I/O 任务，并将结果写入 **完成队列（CQ）**。
>
> ​	•	用户进程可以在合适的时机检查 CQ，而**不需要阻塞或频繁轮询内核**。
>
> ✅ **避免了不必要的系统调用，也减少了 CPU 资源浪费！**
>
> 
>
> **零拷贝（Zero Copy），避免不必要的数据拷贝**
>
> 🔹 **传统 I/O 存在数据拷贝问题**
>
> ​	•	传统 read() 需要：
>
> ​	•	内核从磁盘读取数据到**内核缓冲区**
>
> ​	•	然后再拷贝到**用户缓冲区**
>
> ​	•	这种**双重拷贝**增加了 CPU 和内存带宽的消耗。
>
> 🔹 **io_uring 提供 IORING_OP_SEND_ZC 直接从内核缓冲区发送数据**
>
> ​	•	**减少一次数据拷贝，提高性能**。
>
> ​	•	适用于**网络 I/O、文件 I/O 等场景**。
>
> ✅ **降低 CPU 负担，提升 I/O 效率！**
>

## 磁盘IO与网络IO的区别

1️⃣传输对象

🔹 **磁盘 I/O**（Disk I/O）：主要是 CPU 与**磁盘存储设备**（HDD、SSD）之间的数据交互，如**读写文件、数据库存取**等。

🔹 **网络 I/O**（Network I/O）：主要是 CPU 与**网络设备**（网卡、交换机）之间的数据交互，如**网络通信、HTTP 请求**等。



**2️⃣ 访问速度和延迟**

🔹 **磁盘 I/O**：

​	•**HDD（机械硬盘）**：访问速度慢（毫秒级），<u>**受磁头寻道和转速影响。**</u>

​	•**SSD（固态硬盘）**：速度比 HDD 快很多（微秒级），但仍然比内存慢。

​	•**缓存机制**：现代操作系统使用**页面缓存**（Page Cache）减少磁盘 I/O 访问次数，提高性能。

🔹 **网络 I/O**：

​	•**局域网（LAN）**：一般延迟在**毫秒级**，带宽较高（如 1Gbps 以上）。

​	•**广域网（WAN/互联网）**：延迟可能达到**几十到几百毫秒**，受物理距离、路由跳数、拥塞等影响。

​	•**流量限制**：网络 I/O 受带宽和网络状态影响，比如丢包、延迟抖动等问题。

✅ **总体来说，磁盘 I/O 受<u>存储介质</u>影响较大，而网络 I/O 受<u>带宽和网络延迟</u>影响较大。**



## 🆕🌟 多个进程打开同一个文件

### 是否使用同一个内核的文件对象

是的，两个进程如果打开同一个文件，通常会使用同一个内核的文件对象（**file object**），但是这取决于具体的操作系统和文件打开模式。

在操作系统的内核层面，文件是由一个**文件描述符**（file descriptor）来标识的。当两个进程打开同一个文件时，内核会为每个进程分配一个文件描述符，指向同一个内核层面的文件对象。这个文件对象包含了文件的元数据（如文件偏移量、文件状态标志等）和与文件相关的资源信息。

- **注意点：**

1️⃣ **文件偏移量**：如果两个进程同时打开文件并进行读写操作，每个进程都会有自己的文件描述符，但它们共享同一个内核文件对象中的文件偏移量（**file offset**）。这意味着一个进程的写操作会影响另一个进程的读写起始位置，从而可能导致数据的冲突或不一致。因此，进程之间需要注意同步控制。

2️⃣ **独立文件描述符**：虽然多个进程共享同一个内核文件对象，但每个进程会有独立的文件描述符表项，因此它们可以独立地管理自己的文件描述符。也就是说，它们的文件描述符与文件对象的映射是独立的，但是文件对象的状态（如文件的当前偏移量）是共享的。

3️⃣ **文件锁**：如果两个进程需要并发地读写同一个文件，操作系统提供了文件锁的机制（如flock、fcntl等），可以用于协调文件的访问，防止同时读写造成冲突。

### 产生冲突如何解决？

1. **文件锁定**：使用文件锁（如**flock**）来确保在一个进程写入文件时，其他进程无法进行读写操作。

2. **互斥机制**：利用**进程间通信**（IPC）或共享内存等方式来协调进程之间的读写顺序。



### 文件锁机制

#### flock（文件锁）

flock是一个用于文件锁定的系统调用，可以用来对整个文件加锁，确保在某一时刻只有一个进程可以访问文件。flock是基于文件描述符的，因此它能锁定打开的文件。

**常用操作：**

- **LOCK_SH**：共享锁，允许多个进程同时读取文件，但不允许写入。

- **LOCK_EX**：排他锁，只允许一个进程对文件进行写入操作。

- **LOCK_UN**：解锁。

```c
#include <fcntl.h>
#include <unistd.h>
#include <stdio.h>

int main() {
    int fd = open("example.txt", O_RDWR);
    if (fd == -1) {
        perror("open");
        return 1;
    }

    // 设置排他锁
    if (flock(fd, LOCK_EX) != 0) {
        perror("flock");
        close(fd);
        return 1;
    }

    printf("Locked the file, performing write operations...\n");
    // 在此执行文件写操作

    // 解锁文件
    if (flock(fd, LOCK_UN) != 0) {
        perror("flock unlock");
    }

    close(fd);
    return 0;
}
```

这个例子中，flock(fd, LOCK_EX)会对文件进行排他锁定，保证其他进程无法同时修改文件。当写操作完成后，使用flock(fd, LOCK_UN)来解锁文件。

#### fcntl（文件描述符锁）

fcntl是一个更灵活的文件锁定机制，相比flock，它提供了更多的控制选项，如锁定文件的特定区域（例如锁定文件的一部分）。

**常用操作：**

- **F_SETLK**：设置锁定，如果锁定失败则返回错误。

- **F_SETLKW**：设置锁定，如果锁定失败则阻塞等待，直到获得锁。

- **F_GETLK**：获取锁的信息。

```c
#include <fcntl.h>
#include <unistd.h>
#include <stdio.h>

int main() {
    int fd = open("example.txt", O_RDWR);
    if (fd == -1) {
        perror("open");
        return 1;
    }

    struct flock lock;
    lock.l_type = F_WRLCK; // 写锁
    lock.l_whence = SEEK_SET;
    lock.l_start = 0; // 锁定从文件开始的部分
    lock.l_len = 0;   // 锁定整个文件

    // 设置锁
    if (fcntl(fd, F_SETLK, &lock) == -1) {
        perror("fcntl");
        close(fd);
        return 1;
    }

    printf("Locked the file, performing write operations...\n");
    // 在此执行文件写操作

    // 解锁
    lock.l_type = F_UNLCK; // 解锁
    if (fcntl(fd, F_SETLK, &lock) == -1) {
        perror("fcntl unlock");
    }

    close(fd);
    return 0;
}
```

在这个例子中，使用fcntl来设置写锁（F_WRLCK），锁定整个文件。通过fcntl(fd, F_SETLK, &lock)来申请锁，当文件已经被锁定时，fcntl会返回失败。如果要阻塞等待锁的获得，可以使用F_SETLKW。

**总结**

​	•	**flock** 锁定整个文件，适合用于进程间的文件访问控制，操作简单，但功能相对较少。

​	•	**fcntl** 锁定文件的部分区域，提供了更细粒度的控制，灵活性较强，但需要更复杂的配置。

| 特性                    | `flock`               | `fcntl`             |
| :---------------------- | :-------------------- | :------------------ |
| **锁定范围**            | 整个文件              | 文件区域（记录锁）  |
| **标准**                | BSD                   | POSIX               |
| **锁继承**              | 子进程继承            | 子进程不继承        |
| **网络文件系统（NFS）** | 部分系统不支持        | 通常支持            |
| **多线程**              | 进程级锁，线程共享    | 进程级锁，线程共享  |
| **锁检测**              | 与 `fcntl` 锁互不影响 | 独立于 `flock` 机制 |

# 其他

## Linux常用命令

1️⃣ 日常操作：ls、mv、cd、rm、pwd、grep

2️⃣ 系统相关：

- **ps** - 查看当前系统进程。

​	例如：ps aux 显示所有进程，ps -ef 显示完整的进程列表。

- **top** - 显示系统资源占用情况，实时监控系统进程。

- **df** - 显示磁盘空间使用情况。

​	例如：df -h 以人类可读的格式显示磁盘使用情况。

- **kill**

3️⃣ 网络相关：

- **netstat/ss**  

  `-n`: 以数字形式显示地址和端口号（不解析域名，加快速度）

  `-a`:显示所有连接和监听状态。

  `-t/-u`:指定协议

  `-l`：显示监听的端口

  `-p`：显示每个连接所属的进程。

- **curl**

- **ping**

- **tcpdump：**捕获网络数据包，分析网络流量。

  示例：`tcpdump -i eth0` 捕获指定网卡的数据包。

- **ssh**







## 软硬连接区别

1️⃣ **文件结构与存储方式**

​	•	**软连接**：拥有自己的 inode，存储的是目标文件的路径，类似于 Windows 的快捷方式。

​	•	**硬连接**：多个文件目录项指向同一个 **inode**，共享同一份数据。



2️⃣ **是否依赖原文件**

​	•	**软连接**：依赖原文件，若原文件删除或移动，软连接会失效（变成 **断链**）。

​	•	**硬连接**：独立于原文件，即使删除原文件，硬连接仍然可以访问数据。



3️⃣ **是否可用于目录**

​	•	**软连接**：可以指向目录或文件。

​	•	**硬连接**：**不能** 指向目录（防止循环引用破坏文件系统结构）。



```bash
# 创建软连接
ln -s 原文件 软链接名

# 创建硬连接
ln 原文件 硬链接名
```

## 静态链接和动态链接的区别

1️⃣ **静态链接：**

​	•	**链接时机：** 静态链接是在编译期间（编译时）将所有需要的库代码嵌入到目标程序中。也就是说，编译器会将静态库（.a 或 .lib 文件）中的代码与源代码合并，生成一个独立的可执行文件（.exe）。

​	•	**文件大小：** 静态链接会使得生成的可执行文件变得较大，因为所有的代码和库都已经被包含进了最终的可执行文件中。

​	•	**执行时依赖：** 执行时不需要依赖外部库文件，因为所有的代码都已经被静态地链接到可执行文件中。

2️⃣ **动态链接：**

​	•	**链接时机：** 动态链接是在程序运行时（运行时）将外部库与可执行文件连接起来。程序会在启动时加载动态链接库（DLL 或 .so 文件）到内存中，然后链接使用这些库的函数。

​	•	**文件大小：** 动态链接生成的可执行文件较小，因为它只是包含了库函数的引用，实际的库代码存储在外部的动态链接库文件中。

​	•	**执行时依赖：** 执行时需要依赖外部的动态链接库（DLL 或 .so 文件）。如果缺少这些库文件，程序就无法启动或运行。

## 软/硬中断

- 硬中断：指由硬件设备触发的一种中断机制，主要用于通知操作系统需要立即处理某个事件，确保计算机对外部设备的请求作出快速响应，例如键盘输入、鼠标点击、网络数据包到达等。
- 软中断：一种由软件触发的中断机制，用于在内核态处理某些无需立即执行的任务，由系统内核线程（`ksoftirqd`）执行`

示例：

> **硬中断与软中断的配合步骤**
>
> ​	1.	**硬中断触发**：
>
> ​	•	网卡收到网络数据包后，发送一个中断信号给 CPU。
>
> ​	•	CPU 响应中断信号，暂停当前任务，跳转到网卡的硬中断处理程序。
>
> ​	2.	**硬中断处理程序**：
>
> ​	•	硬中断处理程序快速执行以下操作：
>
> ​	•	**确认中断**：检查网卡状态，确定中断来源（如数据包到达）。
>
> ​	•	**数据缓存**：从网卡缓冲区中将数据包复制到内存中的一个环形缓冲区（ring buffer）。
>
> ​	•	**触发软中断**：标记一个软中断请求（例如在 Linux 中触发 NET_RX_SOFTIRQ）。
>
> ​	•	硬中断处理完成后，迅速返回，以避免长时间占用 CPU。
>
> ​	3.	**软中断处理**：
>
> ​	•	系统在稍后的时间段（如退出硬中断上下文、任务调度时）检查是否有软中断需要处理。
>
> ​	•	如果有，调度软中断处理程序执行以下任务：
>
> ​	•	**解析数据包**：从环形缓冲区中读取数据包。
>
> ​	•	**协议栈处理**：将数据包传递给操作系统的网络协议栈，进行 IP、TCP 等协议的解析。
>
> ​	•	**通知用户程序**：将解析后的数据传递给用户空间的应用程序。



## 中断与信号









## 函数调用的过程 & 相关寄存器

https://www.bilibili.com/video/BV19X4y1P7Pn/?spm_id_from=333.337.search-card.all.click&vd_source=286ca0546d1a508d3fb7c6862b91dafc



## 栈和堆的区别，为什么栈快？

**1️⃣ 堆（Heap）与栈（Stack）的区别**



堆和栈是程序运行时管理内存的两种方式，它们的主要区别如下：

| **属性**     | **栈（Stack）**                       | **堆（Heap）**                                               |
| ------------ | ------------------------------------- | ------------------------------------------------------------ |
| **内存分配** | 由编译器自动分配和释放，内存连续      | 由程序员手动申请 (malloc/new) 和释放 (free/delete)，内存快分散 |
| **访问方式** | 直接通过栈指针 (ESP/RSP) 访问，速度快 | 通过指针间接访问，访问速度较慢                               |
| **增长方向** | 地址**由高向低**增长（向下增长）      | 地址**由低向高**增长（向上增长）                             |
| **生命周期** | 作用域结束后自动释放，管理方便        | 直到 free/delete 才释放，容易导致内存泄漏                    |

**2️⃣ 为什么栈操作比堆快？**

**🔹 结构简单，分配和释放高效**

​	•	**栈**：只需修改 **栈指针（ESP/RSP）**，分配和释放只需加减操作，时间复杂度为 **O(1)**。

​	•	**堆**：涉及 **复杂的内存管理**，操作系统需要维护 **自由链表、页表等数据结构**，时间复杂度通常为 **O(log n) 或更高**。

**🔹 CPU 缓存友好**

​	•	栈上的数据 **局部性好**（**spatial locality**），访问**连续地址**，CPU 缓存命中率高。

​	•	堆上的数据往往**分布不连续**，容易导致 **CPU cache miss**，降低访问速度。

**🔹 直接寻址 vs. 间接寻址**

​	•	**栈变量** 直接通过栈指针 **ESP/RSP** 计算地址，读取/写入数据更快。

​	•	**堆变量** 需要先通过指针找到 **动态分配的地址**，再访问数据，多了一次 **间接寻址**，导致性能下降。

🔹 **系统调用与上下文切换**：

​	•	**栈**：常规操作无需系统调用（内存预先分配）。

​	•	**堆**：空间不足时需通过`brk`/`mmap`等系统调用扩展堆，涉及用户态到内核态切换。

**3️⃣ 什么时候用栈？什么时候用堆？**



✅ **使用栈**：局部变量；占用内存小，生命周期短；递归调用（函数调用帧会入栈）

✅ **使用堆**：

​	•	**大对象**（如 int* p = new int[1000000];），栈内存有限，无法放入大数组

​	•	**不确定大小的对象**（如 std::vector<int>，动态增长）

​	•	**对象需要跨函数生命周期**（如 malloc 分配的内存，需要手动释放）



## 单核CPU什么情况适合开多个线程

> 背景
>
> 单核CPU意味着只有一个物理核心，同一时间只能执行一个线程。这时候操作系统会通过时间片轮转等方式进行线程调度，让多个线程交替执行，看起来像是同时运行。

1️⃣ **I/O 密集型任务**

例如文件读写、网络请求、数据库查询等。这些操作通常涉及等待 I/O 设备响应，CPU 可能处于空闲状态，此时可以让其他线程执行计算或处理其他 I/O 操作，提高系统利用率。

2️⃣**异步任务与事件驱动**

- 定时任务（如每隔1分钟保存数据）
- 事件监听（如监听键盘快捷键）

3️⃣ **提升程序响应性**

- 图形界面程序需要后台执行耗时计算，同时保持界面流畅。









## 用户态-内核态切换







## 锁

### **1️⃣ futex 的工作原理**

🔹 futex 主要用于**线程间同步**，在多线程环境下，多个线程可能需要对共享资源进行加锁和解锁，而传统锁机制（如 pthread_mutex）可能会导致频繁的**用户态-内核态切换**，影响性能。

🔹 futex 通过**用户态自旋**+**内核态挂起**的方式优化锁机制：

​	1.	**快速路径（用户态）**：

​	•	线程尝试在**用户态**直接修改共享变量（如 atomic 操作）。

​	•	如果资源可用（锁未被占用），直接获取锁，**不进入内核**。

​	2.	**慢速路径（内核态）**（仅在竞争激烈时触发）：

​	•	如果资源已被占用，线程调用 futex 系统调用，请求内核**将自己挂起**，等待资源可用。

​	•	当资源释放时，内核唤醒等待的线程，重新进入用户态竞争资源。

✅ **这样避免了不必要的系统调用，提高了锁的性能！**

💡 futex **本身并不是锁，而是用来优化锁的实现**。许多用户态锁（如 pthread_mutex）的底层实现都依赖于 futex，它可以用于：

**互斥锁（mutex）**、**读写锁（rwlock）**、**条件变量（condition variable）**、**信号量（semaphore）**

### 2️⃣自旋锁

**旋锁（Spinlock）** 是一种轻量级的锁，在等待锁释放时，线程不会进入睡眠状态，而是**不断轮询检查锁的状态**，直到获取锁。

适用于 **短时间锁竞争**，避免因上下文切换带来的系统调用开销。

🚀 自旋锁（Spinlock）完全运行在 **用户态**，不会引发**用户态到内核态的转换**，这也是它相比 mutex（互斥锁）更高效的原因之一。



### 活锁

活锁（Livelock）是一种并发编程中的问题，指的是<u>多个线程或进程在执行过程中不断响应彼此的状态变化</u>，但实际无法推进任务，导致系统“卡住”但并未完全停止。

**活锁是“动态死锁”——它看似在运行，但始终没有进展**。

💡**解决方法**：

- 增加随机延时，避免同时重试
- 限制重试次数，放入死信队列
- 设置优先级，给某些线程获取资源跟高的优先级



### 锁和原子变量的区别

**锁** 提供更通用的同步手段，适用于**多个变量的同步**，但可能造成线程阻塞。

**原子变量** 提供更高效的无锁同步，适用于**单个变量的高并发修改**，但不适用于复杂的同步场景。





